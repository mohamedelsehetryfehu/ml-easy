{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "m5L1Qay8SkDW",
        "KPtqmK1CSq23",
        "nwVl-mqq37AY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedelsehetryfehu/ml-easy/blob/main/ml_easy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRUFn4iG2Ydx"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prophet"
      ],
      "metadata": {
        "id": "qOPz_3E9SwgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pystan==2.19.1.1\n",
        "# !pip install convertdate\n",
        "# !pip install lunarcalendar\n",
        "# !pip install holidays==0.10.5\n",
        "# !pip install fbprophet"
      ],
      "metadata": {
        "id": "Xgwn4USmTIrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n"
      ],
      "metadata": {
        "id": "jkjuuXL5znow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "test_case = list(('te', 'r'))\n",
        "\n",
        "# Get current timestamp\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "# Construct filename with timestamp\n",
        "filename = f\"cv_easy_{timestamp}.txt\"\n",
        "# File Saving\n",
        "with open(filename, 'w') as file:\n",
        "    # Serialize and write the tuple to the file\n",
        "    file.write(str(list(test_case)))"
      ],
      "metadata": {
        "id": "2rZq47blzhOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pystan~=2.14\n",
        "# !pip install fbprophet\n",
        "\n",
        "!pip install prophet\n",
        "\n",
        "import prophet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9Pavp4JUIHt",
        "outputId": "870014ce-8c0f-4707-b84c-3c0f2b28580b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: prophet in /usr/local/lib/python3.10/dist-packages (1.1.5)\n",
            "Requirement already satisfied: cmdstanpy>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from prophet) (1.2.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from prophet) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from prophet) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from prophet) (1.5.3)\n",
            "Requirement already satisfied: holidays>=0.25 in /usr/local/lib/python3.10/dist-packages (from prophet) (0.44)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.10/dist-packages (from prophet) (4.66.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from prophet) (6.1.2)\n",
            "Requirement already satisfied: stanio~=0.3.0 in /usr/local/lib/python3.10/dist-packages (from cmdstanpy>=1.0.4->prophet) (0.3.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from holidays>=0.25->prophet) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->prophet) (3.1.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.4->prophet) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->holidays>=0.25->prophet) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from prophet import Prophet\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Function to calculate Root Mean Square Error (RMSE)\n",
        "def calculate_rmse(actual, predicted):\n",
        "    return np.sqrt(mean_squared_error(actual, predicted))\n",
        "\n",
        "# Load the historical time series data\n",
        "# Assuming 'attacks_data' contains the historical attacks data with daily intervals for 500 days\n",
        "# It should be in the form of a list or numpy array\n",
        "# For demonstration, let's assume attacks_data is a list of daily attacks for 500 days\n",
        "#attacks_data = [...]  # Replace [...] with your actual data\n",
        "\n",
        "attacks_data = pd.read_csv('series_data.csv')  # Replace [...] with your actual data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Create a DataFrame with the time series data\n",
        "df = pd.DataFrame({'ds': pd.date_range(start='2015-07-01', periods=len(attacks_data), freq='D'),\n",
        "                   'y': attacks_data[attacks_data.columns[1]]})\n",
        "\n",
        "# Handle missing values by linear interpolation\n",
        "df['y'].interpolate(method='linear', inplace=True)\n",
        "\n",
        "# Detect and handle outliers\n",
        "outliers = df['y'].rolling(window=7, center=True).median()  # Median of a rolling window\n",
        "df['y'] = np.where(abs(df['y'] - outliers) > 3 * outliers.std(), outliers, df['y'])\n",
        "\n",
        "# Define the Prophet model\n",
        "prophet_model = Prophet()\n",
        "\n",
        "# Add outlier regressors\n",
        "df['outlier'] = np.where((df['y'] - outliers).abs() > 3 * outliers.std(), 1, 0)\n",
        "df['outlier'] = df['outlier'].fillna(0)  # Fill NaN with 0\n",
        "\n",
        "# Add outlier regressor to Prophet model\n",
        "prophet_model.add_regressor('outlier')\n",
        "\n",
        "# Fit the model\n",
        "prophet_model.fit(df)\n",
        "\n",
        "# Forecast the attacks for the next 50 days\n",
        "future = prophet_model.make_future_dataframe(periods=50)\n",
        "future['outlier'] = 0  # Assuming no outliers in the future\n",
        "forecast = prophet_model.predict(future)\n",
        "\n",
        "# Extracting forecasted values for the next 50 days\n",
        "forecasted_attacks = forecast.tail(50)['yhat'].values\n",
        "\n",
        "# Print the forecasted attacks\n",
        "print(\"Forecasted attacks for the next 50 days:\")\n",
        "print(forecasted_attacks)\n",
        "\n",
        "# Evaluate the model using RMSE\n",
        "# Assuming you have actual values for the next 50 days stored in 'actual_attacks'\n",
        "actual_attacks = [2.0, 12.0, 13.0, 1.0, 10.0, 8.0, 6.0, 6.0, 6.0, 8.0, 9.0, 6.0, 1.0, 12.0, 11.0, 7.0, 5.0, 12.0, 8.0, 7.0, 15.0, 11.0, 9.0, 7.0, 9.0, 6.0, 8.0, 13.0, 8.0, 5.0, 12.0, 10.0, 7.0, 7.0, 11.0, 7.0, 14.0, 11.0, 3.0, 10.0, 5.0, 14.0, 8.0, 11.0, 8.0, 24.0, 10.0, 15.0, 12.0, 11.0] # Replace [...] with actual values for the next 50 days\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = calculate_rmse(actual_attacks, forecasted_attacks)\n",
        "print(\"Root Mean Square Error (RMSE):\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnR5GCU8SwFb",
        "outputId": "b996818a-e849-4a6e-946b-e349434947ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:prophet:Disabling yearly seasonality. Run prophet with yearly_seasonality=True to override this.\n",
            "INFO:prophet:Disabling daily seasonality. Run prophet with daily_seasonality=True to override this.\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmplbcmg7je/y4xx6md8.json\n",
            "DEBUG:cmdstanpy:input tempfile: /tmp/tmplbcmg7je/ebp3fsch.json\n",
            "DEBUG:cmdstanpy:idx 0\n",
            "DEBUG:cmdstanpy:running CmdStan, num_threads: None\n",
            "DEBUG:cmdstanpy:CmdStan args: ['/usr/local/lib/python3.10/dist-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=14625', 'data', 'file=/tmp/tmplbcmg7je/y4xx6md8.json', 'init=/tmp/tmplbcmg7je/ebp3fsch.json', 'output', 'file=/tmp/tmplbcmg7je/prophet_model7gbrh5gw/prophet_model-20240307195423.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
            "19:54:23 - cmdstanpy - INFO - Chain [1] start processing\n",
            "INFO:cmdstanpy:Chain [1] start processing\n",
            "19:54:23 - cmdstanpy - INFO - Chain [1] done processing\n",
            "INFO:cmdstanpy:Chain [1] done processing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forecasted attacks for the next 50 days:\n",
            "[8.53495795 8.67444828 7.86234096 8.00184932 7.94901255 8.49999046\n",
            " 8.19631111 8.53218658 8.67167691 7.85956959 7.99907795 7.94624118\n",
            " 8.49721909 8.19353974 8.52941521 8.66890554 7.85679822 7.99630658\n",
            " 7.94346981 8.49444772 8.19076837 8.52664384 8.66613417 7.85402685\n",
            " 7.99353521 7.94069844 8.49167635 8.187997   8.52387247 8.6633628\n",
            " 7.85125548 7.99076384 7.93792707 8.48890498 8.18522563 8.5211011\n",
            " 8.66059143 7.84848411 7.98799247 7.9351557  8.48613361 8.18245426\n",
            " 8.51832973 8.65782006 7.84571274 7.9852211  7.93238433 8.48336224\n",
            " 8.17968289 8.51555836]\n",
            "Root Mean Square Error (RMSE): 4.088910615624118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SES Method"
      ],
      "metadata": {
        "id": "m5L1Qay8SkDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.signal import medfilt\n",
        "\n",
        "# Function to calculate Root Mean Square Error (RMSE)\n",
        "def calculate_rmse(actual, predicted):\n",
        "    return np.sqrt(mean_squared_error(actual, predicted))\n",
        "\n",
        "# Load the historical time series data\n",
        "# Assuming 'attacks_data' contains the historical attacks data with daily intervals for 500 days\n",
        "# It should be in the form of a list or numpy array\n",
        "# For demonstration, let's assume attacks_data is a list of daily attacks for 500 days\n",
        "\n",
        "data = pd.read_csv('series_data.csv')  # Replace [...] with your actual data\n",
        "\n",
        "selected_data = data['visits'].astype(np.float32)\n",
        "\n",
        "#selected_data = data['visits'][np.random.choice(data['visits'].shape[0], size=400, replace=False), :]\n",
        "\n",
        "# Handle missing values using interpolation\n",
        "attacks_data = np.array(selected_data)\n",
        "missing_indices = np.isnan(attacks_data)\n",
        "if np.any(missing_indices):\n",
        "    attacks_data[missing_indices] = np.interp(np.flatnonzero(missing_indices),\n",
        "                                              np.flatnonzero(~missing_indices),\n",
        "                                              attacks_data[~missing_indices])\n",
        "\n",
        "# Handle outliers using median filtering\n",
        "attacks_data = medfilt(attacks_data, kernel_size=5)  # Adjust kernel size as needed\n",
        "\n",
        "\n",
        "\n",
        "# Define the SES model\n",
        "ses_model = SimpleExpSmoothing(attacks_data)\n",
        "\n",
        "# Fit the model\n",
        "ses_fit = ses_model.fit()\n",
        "\n",
        "# Forecast the attacks for the next 50 days\n",
        "forecasted_attacks = ses_fit.forecast(steps=50)\n",
        "\n",
        "# Print the forecasted attacks\n",
        "print(\"Forecasted attacks for the next 50 days:\")\n",
        "print(forecasted_attacks)\n",
        "\n",
        "# Evaluate the model using RMSE\n",
        "# Assuming you have actual values for the next 50 days stored in 'actual_attacks'\n",
        "actual_attacks = [2.0, 12.0, 13.0, 1.0, 10.0, 8.0, 6.0, 6.0, 6.0, 8.0, 9.0, 6.0, 1.0, 12.0, 11.0, 7.0, 5.0, 12.0, 8.0, 7.0, 15.0, 11.0, 9.0, 7.0, 9.0, 6.0, 8.0, 13.0, 8.0, 5.0, 12.0, 10.0, 7.0, 7.0, 11.0, 7.0, 14.0, 11.0, 3.0, 10.0, 5.0, 14.0, 8.0, 11.0, 8.0, 24.0, 10.0, 15.0, 12.0, 11.0]  # Replace [...] with actual values for the next 50 days\n",
        "\n",
        "# Calculate RMSE\n",
        "rmse = calculate_rmse(actual_attacks, forecasted_attacks)\n",
        "print(\"Root Mean Square Error (RMSE):\", rmse)"
      ],
      "metadata": {
        "id": "88pBqUQu09Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM"
      ],
      "metadata": {
        "id": "KPtqmK1CSq23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import math\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import os"
      ],
      "metadata": {
        "id": "av8D9hoB3WHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from statsmodels.tsa.holtwinters import SimpleExpSmoothing\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.signal import medfilt"
      ],
      "metadata": {
        "id": "T0Y5S_qQ0_EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qoa_uuAv09S4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'path/to/your/folder' with the actual path within your Drive\n",
        "os.chdir('/content/drive/MyDrive/Dell/Dataset')"
      ],
      "metadata": {
        "id": "WUxHuGyH3b2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_forecast(y_true, y_pred):\n",
        "\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = math.sqrt(mse)\n",
        "    return rmse"
      ],
      "metadata": {
        "id": "QRG3dvBhK7uN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the dataset\n",
        "data = pd.read_csv('series_data.csv')"
      ],
      "metadata": {
        "id": "NFFyg63QSKrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "# Convert timestamp to datetime\n",
        "data['timestamp'] = pd.to_datetime(data['timestamp'])"
      ],
      "metadata": {
        "id": "ASkcegx2SQDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering\n",
        "# Extract relevant features\n",
        "data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
        "data['month'] = data['timestamp'].dt.month\n",
        "data['day'] = data['timestamp'].dt.day"
      ],
      "metadata": {
        "id": "eaDF38LySR7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['visits'] = data['visits'].astype(np.float32)"
      ],
      "metadata": {
        "id": "aLyT7tsmk3hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "scaler = MinMaxScaler()\n",
        "data['visits'] = scaler.fit_transform(data['visits'].values.reshape(-1,1))"
      ],
      "metadata": {
        "id": "lqjLhkr1STD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for LSTM\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:i + seq_length])\n",
        "        y.append(data[i + seq_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "seq_length = 30\n",
        "X, y = create_sequences(data['visits'].values, seq_length)"
      ],
      "metadata": {
        "id": "b63tuF2jSUHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_iaeeJoFkzhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets to match the forecast horizon\n",
        "split = len(data) - 50\n",
        "X_train, X_test = X[:split], X[split:]\n",
        "y_train, y_test = y[:split], y[split:]"
      ],
      "metadata": {
        "id": "zh1zgPvLSVgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwFfdhI_C8Iq",
        "outputId": "0e7df5a1-67fd-4d9b-89d2-6f82e89a8193"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(450, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(seq_length, 1)\n",
        "input_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdxKdebvfjhY",
        "outputId": "f1fb25c3-5410-4042-8932-9d00e1ddc38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, activation='relu', input_shape=(seq_length, 1)))\n",
        "model.add(Dense(units=1))\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "qs8vrPR4SWf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32)"
      ],
      "metadata": {
        "id": "k08s-npUSXea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forecasting\n",
        "forecast = []\n",
        "current_batch = X_test[0].reshape((1, seq_length, 1))\n",
        "print(current_batch.shape)\n",
        "\n",
        "\n",
        "for i in range(50):  # Iterate 50 times for 50 days forecast\n",
        "    current_pred = model.predict(current_batch)[0]\n",
        "    forecast.append(current_pred)\n",
        "    current_batch = np.append(current_batch[:,1:,:],[[current_pred]],axis=1)"
      ],
      "metadata": {
        "id": "Q6NfC1sHSYaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse transform the forecasted values\n",
        "forecast = scaler.inverse_transform(np.array(forecast).reshape(-1,1))"
      ],
      "metadata": {
        "id": "LcrOEzIUSZyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure y_test_trimmed contains the next 50 days of attack data\n",
        "y_test_trimmed = data['visits'][-50:].values.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "A-PmhPK0Sag7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the forecast\n",
        "rmse = evaluate_forecast(y_test_trimmed, forecast)\n",
        "print(\"Root Mean Square Error (RMSE):\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDeM1J_NSbgc",
        "outputId": "58f74d1a-10d1-4be5-f6cb-e1a928dc0b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Square Error (RMSE): 8.93589416162554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_flat = [item for sublist in forecast for item in sublist]\n",
        "\n",
        "print(\"Forecast for the next 50 days:\")\n",
        "print(forecast_flat)"
      ],
      "metadata": {
        "id": "toV-aj3hMDys",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68fd10e0-c4f3-4d6a-c483-3fa98855757b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forecast for the next 50 days:\n",
            "[8.994633, 9.012736, 9.027131, 9.039193, 9.04888, 9.057257, 9.064123, 9.070072, 9.074838, 9.07904, 9.082726, 9.085924, 9.088574, 9.090654, 9.092623, 9.094451, 9.095683, 9.096578, 9.097241, 9.09813, 9.099025, 9.09956, 9.100189, 9.100512, 9.100839, 9.101118, 9.101398, 9.101806, 9.101876, 9.101847, 9.102051, 9.102179, 9.102289, 9.102383, 9.102463, 9.102532, 9.1025915, 9.102641, 9.102686, 9.102722, 9.102756, 9.102781, 9.102806, 9.102826, 9.102843, 9.102859, 9.102872, 9.102882, 9.102891, 9.1029]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('lstm_attack_forecast_model_mleasy.h5')"
      ],
      "metadata": {
        "id": "0m7ebd1G_K0K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e126f8-86c2-40aa-9e58-6a68a575e25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert to Tensorflow Lite"
      ],
      "metadata": {
        "id": "nwVl-mqq37AY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-cpu"
      ],
      "metadata": {
        "id": "jnFo28iM3IYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "JkPFaziX3MkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model('lstm_attack_forecast_model_mleasy.h5')"
      ],
      "metadata": {
        "id": "Yrwofx-qtn6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('lstm_attack_forecast_model_mleasy.h5')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "# converter._experimental_lower_tensor_list_ops = False\n",
        "converter.experimental_new_converter = True\n",
        "tflite_model = converter.convert()\n",
        "open(\"lstm_attack_forecast_model3.tflite\", \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw6jRRCF3M7N",
        "outputId": "1ef0a095-4de9-413a-9668-a4e523107ec7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52152"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('lstm_attack_forecast_model_mleasy.h5')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [ tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "                                       tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "                                        ]\n",
        "tflite_model = converter.convert()\n",
        "with open(\"best63.tflite\", 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "EAYufSx8xKDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path='lstm_attack_forecast_model3.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(input_details[0]['shape'])\n",
        "print(X_test.shape)\n",
        "\n",
        "\n",
        "# Reshape and convert to float32\n",
        "#X_test = np.reshape(X_test.astype(np.float32), (20, 30, 1))\n",
        "\n",
        "# Set input tensor\n",
        "interpreter.set_tensor(input_details[0]['shape'], X_test)\n",
        "\n",
        "# Run inference\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get output tensor\n",
        "forecast = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "# Inverse transform the forecasted values\n",
        "forecast = scaler.inverse_transform(forecast)\n",
        "\n",
        "# Flatten the forecast list\n",
        "forecast_flat = forecast.flatten()"
      ],
      "metadata": {
        "id": "GI5FwbqH3ZoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "0Qt3FMcT9pJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def solve_ml_easy(data: pd.DataFrame) -> list:\n",
        "\n",
        "    # Convert input to DataFrame\n",
        "    #data = pd.DataFrame(input)\n",
        "    #data = input\n",
        "    # Drop rows with NaN values\n",
        "    #data.dropna(inplace=True)\n",
        "\n",
        "    # Convert timestamp to datetime\n",
        "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "\n",
        "    # Fill in missing dates with zero attacks\n",
        "    all_dates = pd.date_range(start=data['timestamp'].min(), end=data['timestamp'].max())\n",
        "    data.set_index('timestamp', inplace=True)\n",
        "    data = data.reindex(all_dates, fill_value=0)\n",
        "\n",
        "    # Smooth out any sudden spikes or outliers\n",
        "    data['visits'] = data['visits'].rolling(window=7, min_periods=1).mean()\n",
        "\n",
        "    # Normalize the data\n",
        "    scaler = MinMaxScaler()\n",
        "    data['visits_normalized'] = scaler.fit_transform(data['visits'].values.reshape(-1, 1))\n",
        "\n",
        "    # Prepare data for LSTM\n",
        "    seq_length = 30\n",
        "    X_test = []\n",
        "\n",
        "    for i in range(len(data) - seq_length, len(data)):\n",
        "        X_test.append(data['visits_normalized'][i-seq_length:i].values)\n",
        "\n",
        "    X_test = np.array(X_test).astype(np.float32)  # Convert to np.float32\n",
        "\n",
        "    # #Load the saved model\n",
        "    # loaded_model = load_model('lstm_attack_forecast_model.h5')\n",
        "\n",
        "    # #Perform prediction\n",
        "    # forecast = loaded_model.predict(X_test)\n",
        "\n",
        "\n",
        "    #X_test = X_test.values.reshape(-1,1,1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Load the TFLite model\n",
        "    interpreter = tf.lite.Interpreter(model_path='best63.tflite')\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    print(input_details[0]['shape'])\n",
        "\n",
        "    print(input_details[0]['shape'])\n",
        "    print(X_test.shape)\n",
        "    #print (X_test)\n",
        "\n",
        "    # Set input tensor\n",
        "    interpreter.set_tensor(input_details[0]['shape'], X_test)\n",
        "\n",
        "    # Run inference\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get output tensor\n",
        "    forecast = interpreter.get_tensor(output_details[0]['shape'])\n",
        "\n",
        "    #Inverse transform the forecasted values\n",
        "    forecast = scaler.inverse_transform(forecast)\n",
        "    print (forecast.shape)\n",
        "\n",
        "    # Flatten the forecast list\n",
        "    forecast_flat = forecast.flatten()\n",
        "\n",
        "    # Return the forecasted values for the next 50 days\n",
        "    return forecast_flat.tolist()"
      ],
      "metadata": {
        "id": "PyZc2_m38uWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = pd.read_csv('series_data.csv')\n",
        "\n",
        "sol = solve_ml_easy (input)\n",
        "\n",
        "print (sol)\n",
        "\n"
      ],
      "metadata": {
        "id": "olA6h7n19kNz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}